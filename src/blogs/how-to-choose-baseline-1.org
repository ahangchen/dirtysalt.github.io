#+title: 选用什么方法做baseline-1

前几天在 [[file:20150207-how-to-choose-baseline-0.org][选用什么方法做baseline-0]] 文章里面，我觉得SVM, RF, GBDT, NB, kNN是几类相对来说比较迥异的算法。今天我稍微试验了一下RF和GBDT两个算法，发现GBDT应该从这个集合里面排除。也就是说我们常用算法应该就是SVM, RF, NB和kNN. 

RF和GBDT实验是用scikit-learn提供的数据集合来做的。代码在简书上好像不太适合粘贴，所以放在 [[https://gist.github.com/dirtysalt/5f16102a3798d1ccd15a][github]] 上了。使用数据集合分别是iris和digits. iris两者效果差不多(RF=GBDT=0.98, AdaBoost=0.89)，数据小特征数目也小。而digits差别就比较大，RF准确率0.97,  AdaBoost准确率是0.85, GBDT准确率是0.94，时间上GBDT比RF要长很多。

对于这个结果，我是这么想的。对于Decision Tree一类算法来说，除非问题本身就能够非常好的用决策树来表示，否则Decision Tree结果一般都不太好。原因在于Decision Tree工作方式就是在特定数据集合上，用特定方式顺序选择feature来做切分，如果不引入随机性的话很容易发生过拟合。AdaBoost对数据集合进行resample, 但是对feature没有做筛选没有做顺序选择的改变; GBDT对数据集合进行resample, 对feature有筛选以及但是没有对选择顺序更改; RF对数据进行进行bootstrap, 对feature筛选以及选择顺序更改(Extremely Randomized Trees)。对比来看RF的randomness是最强的，所以效果应该会更高。(我们也可以预期extremely randomized trees可能会比RF更高)

paste code here. `decision tree ensemble methods comparison`.

#+BEGIN_SRC Python
#!/usr/bin/env python
#coding:utf-8
#Copyright (C) dirlt

from sklearn import datasets
iris = datasets.load_iris()
digits = datasets.load_digits()

from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn import cross_validation
from sklearn.metrics import classification_report

# (data, target) = (iris.data, iris.target)
(data, target) = (digits.data, digits.target)
X_tr, X_tt, y_tr, y_tt = cross_validation.train_test_split(data, target, test_size = 0.3, random_state = 0)
 
print '----------RandomForest----------'
clf = RandomForestClassifier(n_estimators = 100, bootstrap = True, oob_score = True)
clf.fit(X_tr, y_tr)
print 'OOB Score = %.4f' % clf.oob_score_
# print 'Feature Importance = %s' % clf.feature_importances_
y_true, y_pred = y_tt, clf.predict(X_tt)
print(classification_report(y_true, y_pred))

print '----------ExtraForest----------'
clf = ExtraTreesClassifier(n_estimators = 100, bootstrap = True, oob_score = True)
clf.fit(X_tr, y_tr)
print 'OOB Score = %.4f' % clf.oob_score_
# print 'Feature Importance = %s' % clf.feature_importances_
y_true, y_pred = y_tt, clf.predict(X_tt)
print(classification_report(y_true, y_pred))

print '----------AdaBoost----------'
clf = AdaBoostClassifier(n_estimators = 100, learning_rate = 0.6, random_state = 0)
clf.fit(X_tr, y_tr)
# print 'Feature Importance = %s' % clf.feature_importances_
y_true, y_pred = y_tt, clf.predict(X_tt)
print(classification_report(y_true, y_pred))

print '----------GradientBoosting----------'
clf = GradientBoostingClassifier(n_estimators = 100, learning_rate = 0.6, random_state = 0)
clf.fit(X_tr, y_tr)
# print 'Feature Importance = %s' % clf.feature_importances_
y_true, y_pred = y_tt, clf.predict(X_tt)
print(classification_report(y_true, y_pred))
#+END_SRC

