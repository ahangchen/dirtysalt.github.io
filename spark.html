<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2016-11-02 三 20:10 -->
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>spark</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="dirtysalt" />
<link rel="shortcut icon" href="http://dirtysalt.info/css/favicon.ico" />
<link rel="stylesheet" type="text/css" href="./css/site.css" />
</head>
<body>
<div id="content">
<h1 class="title">spark</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgheadline1">1. Spark Running Mode</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgheadline1" class="outline-2">
<h2 id="orgheadline1"><span class="section-number-2">1</span> Spark Running Mode</h2>
<div class="outline-text-2" id="text-1">
<p>
spark整体架构如下图:
</p>


<div class="figure">
<p><img src="./images/spark-cluster-overview.png" alt="spark-cluster-overview.png" />
</p>
</div>

<ul class="org-ul">
<li>driver progam # 客户端. 在这里创建sparkcontext, 然后提交任务到cluster上</li>
<li>cluster manager # master节点. 当然这里也可能包括其他资源管理系统比如mesos或yarn.</li>
<li>worker node # worker节点. 在上面会启动executor, 每个executor则会启动多个task. 一个task对应a action on a partition.</li>
</ul>

<p>
根据spark文档中<a href="http://spark.apache.org/docs/latest/cluster-overview.html">Cluster Mode Overview</a> 一节描述, 共有下面几种运行方式
</p>
<ul class="org-ul">
<li>local # 本地模式. master, worker都在一个JVM中.</li>
<li>local cluster # 本地机群模式. master, worker在一个机器上, 但是是不同的JVM</li>
<li>standalone # 独立机群模式. master做资源管理和状态收集.</li>
<li>mesos # 借助mesos来做资源管理</li>
<li>yarn cluster # 借助yarn来做资源管理. driver program运行在yarn集群上</li>
<li>yarn client # 和上面不同的是driver program运行在客户本地.</li>
</ul>

<p>
这些运行方法内部实现原理非常类似. 先看看local cluster和standalone.(因为local将所有东西放在一个JVM里面, 所以许多组件都被省略)
</p>


<div class="figure">
<p><img src="./images/spark-local-cluster-mode.png" alt="spark-local-cluster-mode.png" />
</p>
</div>

<p>
standalone完全一样. 每个worker/executor上运行一个CoarseGrainedExecutorBackend和driver进行通信. driver对应组件是SparkDeploySchedulerBackend, 双方使用Akka来做通信. TaskSchedulerImpl管理整个DAG如何拆分成为tasks以及这些task按照什么顺序执行. task会被序列化发送到executor上, executor反序列化task然后执行, 执行完成后汇报给driver. driver从matser上申请资源, 然后master会在worker上启动executor来提供执行资源. driver还会向master汇报状态.
</p>

<p>
这里顺带说一下spark是如何评估应用使用资源的. spark应用资源申请是以core为单位的(spark.cores.max). 集群启动时worker会检查这个机器有多少core, 然后汇报给master. 同时我们也需要配置每个executor占用多少core(spark.executor.cores). 这样spark在提交应用时候就知道这个应用会使用多少core以及使用多少executor
</p>

<p>
mesos模式分为粗细两种粒度. 粗粒度和local cluster/standalone一样. 应用程序开始便申请executor, 如果没有足够资源不启动. 期间资源完全占据, 直到应用退出executor资源才会归还. 而细粒度则不通, 只要集群中有一些资源给部分executor的话, 那么应用程序就会开始执行任务(task). 任务执行完成之后, 那么executor资源就会归还. 粗粒度是以app/job作为分配单元的, 而细粒度是以task作为分配单元的. 这里的tradeoff是资源使用率以及调度带来的开销.
</p>

<p>
<img src="./images/spark-mesos-coarse-mode.png" alt="spark-mesos-coarse-mode.png" /> <img src="./images/spark-mesos-fine-mode.png" alt="spark-mesos-fine-mode.png" />
</p>

<p>
对于yarn来说只有粗粒度模式. cluster/client在启动executor细节上有所差异. cluster模式中因为driver已经运行在NM上所以可以直接启动其他NM上的executors, 而client必须委托一个NM来创建executors.
</p>

<p>
<img src="./images/spark-yarn-cluster-mode.png" alt="spark-yarn-cluster-mode.png" /> <img src="./images/spark-yarn-client-mode.png" alt="spark-yarn-client-mode.png" />
</p>

<p>
RDD从生成到执行过程, 以及这个过程中使用的组件, 可以参考下图:
</p>
<ul class="org-ul">
<li>SparkContext 用户用来生成RDD</li>
<li>DAGScheduler 
<ul class="org-ul">
<li>将RDD生成Jobs, 并且将Jobs划分成为Stages</li>
<li>然后将Stage细分到Tasks, 提交给TaskScheduler.</li>
</ul></li>
<li>TaskScheduler是执行Tasks的引擎.
<ul class="org-ul">
<li>它会创建一个TaskSetManager来管理这些任务执行顺序(比如locality以及resource考虑)</li>
<li>TaskScheduler收到Tasks执行结果, 将结果汇报给DAGScheduler.</li>
</ul></li>
</ul>


<div class="figure">
<p><img src="./images/spark-rdd-scheduling.jpg" alt="spark-rdd-scheduling.jpg" />
</p>
</div>
</div>
</div>
</div>
</body>
</html>
