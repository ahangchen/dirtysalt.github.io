<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta  http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta  name="viewport" content="width=device-width, initial-scale=1" />
<title>机器学习基石 on Coursera</title>
<meta  name="generator" content="Org-mode" />
<meta  name="author" content="dirtysalt" />
<link rel="shortcut icon" href="http://dirtysalt.info/css/favicon.ico" />
<link rel="stylesheet" type="text/css" href="./css/site.css" />
</head>
<body>
<div id="content">
<h1 class="title">机器学习基石 on Coursera</h1>
<p>
<a href="https://class.coursera.org/ntumlone-002">https://class.coursera.org/ntumlone-002</a>
</p>

<ul class="org-ul">
<li>L1 机器学习介绍
<ul class="org-ul">
<li>和其他三个领域之间的差别和关系</li>
<li><img src="./images/ntuml-ml-related-fields.png" alt="ntuml-ml-related-fields.png" /></li>
</ul></li>
<li>L2 PLA(Perceptron Learning Algorithm) # 算法变形pocket</li>
<li>L3 机器学习分类
<ul class="org-ul">
<li>输出类型分类：classification/regression/structured(结构化)</li>
<li>数据标签分类：supervised/unsupervised/semi-supervised(获得标签代价非常高)/reinforcement(强化，返回反馈满意度)</li>
<li>输入方式分类：batch/online/active. 其中online和active都是顺序处理数据，但是active能够主动提问</li>
<li>输入特征分类：concrete/raw/abstract. abstract相比raw特征更加隐蔽. 转换为concrete特征需要domain-knowledge来做辅助.</li>
</ul></li>
<li>L4-L7 学习可行性分析
<ul class="org-ul">
<li>通常一个模型model会对应很多参数，给定一个参数就对应一个hypothesis. 因此model实际上给出的是一个假设集合hypothesis-set, 我们记为H.</li>
<li>从Hoeffding不等式，到H即hypothesis-set的effective-number/break-point，到更加正式的定义vc-dimension.</li>
<li>vc-dimension只和H有关，或者说只和model有关。vc物理意义是：H处理二分类问题有多少自由度。vc越大说明H选择更多，能力越强，也说明越复杂。</li>
<li>model/H进行训练效果满足不等式 P(|u-v| &gt; e) &lt;= 2 * (2N)^vc * exp(-2 * e^2 * N). 其中vc是H的vc-dimension.</li>
<li>从上面不等式可以看到，vc和N(数据集合大小)之间存在trade-off. vc越大H选择越多，但是需要更多的数据才能找到更好的假设。</li>
<li><img src="./images/ntuml-theoretical-bounds.png" alt="ntuml-theoretical-bounds.png" /></li>
</ul></li>
<li>L8 噪音和误差
<ul class="org-ul">
<li>引入噪音并不会改变H的vc-dimension. 因此即使训练数据里面包含噪音，我们依然能够进行训练和学习。</li>
<li>衡量误差的时候，我们可能会针对false-positive/false-negative给出不同的penalty或者是weight. 这种效果等价于我们对dataset这些错误输入进行virtual-copy.</li>
</ul></li>
<li>L9-11 线性回归，逻辑回归，线性模型
<ul class="org-ul">
<li>线性回归中，使用最小二乘法作为代价函数的话，那么可以使用分析方法计算出w = ((x' * x) ^ -1 * x') * y. 前半部分我们可以称之为pseudo-inverse, 记为x*.</li>
<li>线性回归中，如果将w作用在x上的话就可以求解出预测向量y' = x * x* * y = (x * x*) * y. 我们将(x * x*)称为hat-matrix/H.</li>
<li>逻辑回归的损失函数，通过合适的缩放，可以看做是err0/1分类损失函数的上限。因此逻辑回归函数可以用来做二分分类。</li>
<li>OVA(one-versus-all)来求解K多分类问题：1. 需要跑K个二分类问题，每个二分类问题处理N条记录 2. 如果K太大容易造成数据倾斜.</li>
<li>OVO(one-versus-one)来求解K多分类问题：1. 可以避免OVA出现的数据倾斜问题 2. 需要跑K*(K-1)*0.5个二分类问题，每个二分类问题只处理2*N/K个记录.</li>
</ul></li>
<li>L12 非线性变换</li>
<li>L13-15 过拟合，正则化，验证
<ul class="org-ul">
<li>泛化能力不好表现loww Ein, high Eout. 过拟合表现是lower Ein, higher Eout.</li>
<li>出现过拟合的原因有这些： 1. vc过大 2. 夹杂噪音 3. 数据量不够</li>
<li>即使target-function是10th多项式，那么2th多项式H2给出的结果不一定会比10th多项式H10差。虽然可能Ein(H2) &gt; Ein(H2), 但是更有可能是Eout(H2) &lt; Eout(H10). # 可以看出部分原因我们还没有学习足够多的数据集合，而且对于vc越大的H需要学习数据量越大才能获得较好效果。</li>
<li><img src="./images/ntuml-overfitting-learning-curve.png" alt="ntuml-overfitting-learning-curve.png" /></li>
<li>噪音可以分为两类：stochastic noise(随机噪音)表示数据集合本身偏差引入的，deterministic noise(确定噪音)表示target-function自身复杂性引入的。# 比如伪随机数(噪音多)就是使用复杂的(高阶)函数来模拟产生的.</li>
<li><img src="./images/ntuml-overfitting-noise-and-data-size.png" alt="ntuml-overfitting-noise-and-data-size.png" /></li>
<li>解决过拟合问题有下面几个手段 1. 先从简单模型入手 2. data cleaning/pruning 3. data hinting 4.regularization 5. validation</li>
<li>引入regularization非常有启发性：通过限制w'w &lt;= C，使用Lagrange Multiplier(拉格朗日乘子法), 推导出weight-decay regularization也就是ridge regression</li>
<li>如果需要使用多项式变换的话，应该选用Legendre多项式，可以认为这些多项式之间是相互"正交"的。因为如果我们只是用x^n来做多项式的话，那么高次方的x^n值通常很小，因此要求对应项的w很大。而这与regularization相悖，因为正规化项要求w应该尽可能小。</li>
<li>通常使用5~10-Fold来做CV. 训练像是初赛，CV则像是复赛，只有最终测试才是决赛。所以我们要关注应该是测试效果，而不是验证效果。</li>
</ul></li>
<li>L16 学习三原则
<ul class="org-ul">
<li>Sampling Bias（采样偏差）表明我们需要仔细了解数据收集产生的过程。如果收集产生过程本身就有偏差的话，那么我们在训练和验证阶段就需要将偏差考虑进去。</li>
<li>Data Snooping（数据窥视）表明我们不能将测试数据加入训练/CV集合，否则会影响训练效果。机器会学习到这些测试数据的特性，影响到泛化能力；不要过早地去查看数据来做出假设和模型，但是有时候确实也需要通过观察数据来选择features和模型，因此我们必须在验证的时候严格把关。按照作者的话说应该就是careful balance between data-driven modeling(snooping) and validation(no-snooping).</li>
</ul></li>
</ul>

<hr  />
<p>
机器学习和其他领域之间的差别和关系
</p>

<p>
机器学习和数据挖掘
</p>


<div class="figure">
<p><img src="./images/ntuml-ml-vs-dm.png" alt="ntuml-ml-vs-dm.png" />
</p>
</div>

<p>
机器学习和人工智能
</p>


<div class="figure">
<p><img src="./images/ntuml-ml-vs-ai.png" alt="ntuml-ml-vs-ai.png" />
</p>
</div>

<p>
机器学习和统计学
</p>


<div class="figure">
<p><img src="./images/ntuml-ml-vs-st.png" alt="ntuml-ml-vs-st.png" />
</p>
</div>
</div>
<!-- DISQUS BEGIN --><div id="disqus_thread"></div><script type="text/javascript">/* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * *//* required: replace example with your forum shortname  */var disqus_shortname = 'dirlt';var disqus_identifier = 'ml-foundations.html';var disqus_title = 'ml-foundations.html';var disqus_url = 'http://dirtysalt.info/ml-foundations.html';/* * * DON'T EDIT BELOW THIS LINE * * */(function() {var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);})();</script><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript><a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a><!-- DISQUS END --></body>
</html>
